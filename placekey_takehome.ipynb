{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from placekey.api import PlacekeyAPI\n",
    "import json\n",
    "import polars as pl\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PLACEKEY_API_KEY = os.environ.get('PLACEKEY_API_KEY')  # Store API key in environment variable\n",
    "if not PLACEKEY_API_KEY:\n",
    "    raise ValueError(\"Please set the PLACEKEY_API_KEY environment variable.\")\n",
    "\n",
    "DATA_DIR = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df_for_api(df, column_map):\n",
    "    \"\"\"Prepares a DataFrame for the Placekey API.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        column_map (dict): Mapping of original column names to Placekey API field names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame ready for Placekey API input.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.rename(columns=column_map)[list(column_map.values())]\n",
    "    df[\"iso_country_code\"] = \"US\"\n",
    "    df[\"query_id\"] = df[\"query_id\"].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_placekeys_to_df(df, column_map, join_key, output_filename):\n",
    "    \"\"\"Processes a dataset through the Placekey API.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        column_map (dict): Mapping of column names.\n",
    "        output_filename (str): Name of the CSV file to store Placekeys.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with Placekeys.\n",
    "    \"\"\"\n",
    "    df_for_api = prep_df_for_api(df, column_map)\n",
    "    responses = PlacekeyAPI(PLACEKEY_API_KEY).lookup_placekeys(json.loads(df_for_api.to_json(orient=\"records\")), verbose=True)\n",
    "    placekeys_df = pd.DataFrame(responses)\n",
    "    placekeys_df.to_csv(os.path.join(DATA_DIR, output_filename), index=False)\n",
    "    return df.merge(placekeys_df, left_on=join_key, right_on=\"query_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Blight Violations\n",
    "blight_df = pd.read_csv(os.path.join(DATA_DIR, 'Blight_Violations.csv'))\n",
    "blight_df = blight_df.head(100)\n",
    "blight_df['zip_code'] = blight_df['zip_code'].astype(str)\n",
    "blight_df['state'] = blight_df['state'].astype(str)\n",
    "blight_df['ticket_id'] = blight_df['ticket_id'].astype(str)\n",
    "blight_column_map = {\n",
    "    \"ticket_id\": \"query_id\",\n",
    "    \"violation_address\" : \"street_address\",\n",
    "    \"state\": \"region\",\n",
    "    \"zip_code\": \"postal_code\",\n",
    "    \"Y\" : \"latitude\",\n",
    "    \"X\" : \"longitude\",\n",
    "    \"country\" : \"iso_country_code\",\n",
    "    \"city\" : \"city\"\n",
    "    }\n",
    "blight_df = add_placekeys_to_df(blight_df, blight_column_map, \"ticket_id\", \"placekeys_Blight_Violations.csv\")\n",
    "blight_df.to_csv(os.path.join(DATA_DIR, \"Blight_Violations_w_placekeys.csv\"), index=False)\n",
    "\n",
    "# Process Property Sales\n",
    "sales_df = pd.read_csv(os.path.join(DATA_DIR, 'Property_Sales.csv'))\n",
    "sales_df['sale_id'] = sales_df['sale_id'].astype(str)\n",
    "sales_df['city'] = 'Detroit'\n",
    "sales_df['iso_country_code'] = 'US'\n",
    "sales_df['region'] = 'MI'\n",
    "Property_Sales_column_map = {\n",
    "    \"sale_id\": \"query_id\",\n",
    "    \"address\" : \"street_address\",\n",
    "    \"Y\" : \"latitude\",\n",
    "    \"X\" : \"longitude\",\n",
    "    \"city\": \"city\",\n",
    "    \"region\": \"region\",\n",
    "    \"iso_country_code\": \"iso_country_code\"\n",
    "    }\n",
    "sales_df = add_placekeys_to_df(sales_df, Property_Sales_column_map, \"sale_id\", \"placekeys_Property_Sales.csv\")\n",
    "sales_df.to_csv(os.path.join(DATA_DIR, \"Property_Sales_w_placekeys.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "blight_df = pl.read_csv(os.path.join(DATA_DIR, \"Blight_Violations_w_placekeys.csv\"),infer_schema_length=1000000)\n",
    "blight_df_placekeys = blight_df[\"placekey\"].to_list()\n",
    "blight_df = blight_df.filter(pl.col('placekey').is_not_null())\n",
    "\n",
    "sales_df = pl.read_csv(os.path.join(DATA_DIR, \"Property_Sales_w_placekeys.csv\"),infer_schema_length=1000000)\n",
    "sales_df = sales_df.filter(pl.col('placekey').is_not_null())\n",
    "\n",
    "blight_df_joined_sales_df_placeykey = blight_df.join(sales_df, on=\"placekey\", how=\"inner\")\n",
    "blight_df_joined_sales_df_placeykey.write_csv(os.path.join(DATA_DIR, \"blight_joined_sales_placeykey.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching placekeys: 142,295\n",
      "Percentage of matching placekeys: 33.12%\n",
      "Number of matching hex: 418,265\n",
      "Percentage of matching hex: 97.35%\n"
     ]
    }
   ],
   "source": [
    "sales_placekeys = pd.read_csv(os.path.join(DATA_DIR, \"placekeys_Property_Sales.csv\"))\n",
    "blight_placekeys = pd.read_csv(os.path.join(DATA_DIR, \"placekeys_Blight_Violations.csv\"))\n",
    "sales_placekeys.dropna(subset=['placekey'], inplace=True)\n",
    "blight_placekeys.dropna(subset=['placekey'], inplace=True)\n",
    "\n",
    "# Matching placekeys\n",
    "matching_placekeys = sales_placekeys[\"placekey\"].isin(blight_placekeys[\"placekey\"])\n",
    "print(\"Number of matching placekeys: {:,}\".format(matching_placekeys.sum()))\n",
    "print(\"Percentage of matching placekeys: {:.2f}%\".format((matching_placekeys.sum() / len(sales_placekeys)) * 100))\n",
    "\n",
    "# Same hex match\n",
    "sales_placekeys['hex'] = sales_placekeys['placekey'].str.split('@').str[1]\n",
    "blight_placekeys['hex'] = blight_placekeys['placekey'].str.split('@').str[1]\n",
    "matching_hex = sales_placekeys[\"hex\"].isin(blight_placekeys[\"hex\"])\n",
    "print(\"Number of matching hex: {:,}\".format(matching_hex.sum()))\n",
    "print(\"Percentage of matching hex: {:.2f}%\".format((matching_hex.sum() / len(sales_placekeys)) * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
